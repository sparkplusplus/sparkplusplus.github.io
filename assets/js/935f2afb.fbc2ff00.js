"use strict";(self.webpackChunkdocs_4=self.webpackChunkdocs_4||[]).push([[53],{1109:e=>{e.exports=JSON.parse('{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"defaultSidebar":[{"type":"link","label":"Intro","href":"/","docId":"index"},{"type":"category","label":"Spark Internals","collapsible":true,"collapsed":false,"items":[{"type":"link","label":"Overview","href":"/spark-internals/overview","docId":"spark-internals/overview"},{"type":"category","label":"Spark Planning","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Spark Logical Plan","href":"/spark-internals/plans/spark-logical-plan","docId":"spark-internals/plans/spark-logical-plan"},{"type":"link","label":"Spark Physical Plan","href":"/spark-internals/plans/spark-physical-plan","docId":"spark-internals/plans/spark-physical-plan"},{"type":"link","label":"Catalyst Optimizer","href":"/spark-internals/plans/catalyst-optimizer","docId":"spark-internals/plans/catalyst-optimizer"}]},{"type":"link","label":"Shuffle Details","href":"/spark-internals/shuffle-details","docId":"spark-internals/shuffle-details"},{"type":"link","label":"Architecture","href":"/spark-internals/architecture","docId":"spark-internals/architecture"},{"type":"link","label":"Cache And Checkpoint","href":"/spark-internals/cache-and-checkpoint","docId":"spark-internals/cache-and-checkpoint"},{"type":"link","label":"Broadcast","href":"/spark-internals/broadcast","docId":"spark-internals/broadcast"}],"href":"/spark-internals/"}]},"docs":{"index":{"id":"index","title":"Intro to Spark Internals","description":"This series discuss the design and implementation of Apache Spark, with focuses on its design principles, execution mechanisms, system architecture and performance optimization.","sidebar":"defaultSidebar"},"spark-internals/architecture":{"id":"spark-internals/architecture","title":"Architecture","description":"Prophecy deployment is flexible and supports multiple mechanisms","sidebar":"defaultSidebar"},"spark-internals/broadcast":{"id":"spark-internals/broadcast","title":"Broadcast","description":"Prophecy deployment is flexible and supports multiple mechanisms","sidebar":"defaultSidebar"},"spark-internals/cache-and-checkpoint":{"id":"spark-internals/cache-and-checkpoint","title":"Cache And Checkpoint","description":"Prophecy deployment is flexible and supports multiple mechanisms","sidebar":"defaultSidebar"},"spark-internals/overview":{"id":"spark-internals/overview","title":"Overview","description":"Prophecy deployment is flexible and supports multiple mechanisms","sidebar":"defaultSidebar"},"spark-internals/plans/catalyst-optimizer":{"id":"spark-internals/plans/catalyst-optimizer","title":"Catalyst Optimizer","description":"Prophecy deployment is flexible and supports multiple mechanisms","sidebar":"defaultSidebar"},"spark-internals/plans/spark-logical-plan":{"id":"spark-internals/plans/spark-logical-plan","title":"Spark Logical Plan","description":"Prophecy deployment is flexible and supports multiple mechanisms","sidebar":"defaultSidebar"},"spark-internals/plans/spark-physical-plan":{"id":"spark-internals/plans/spark-physical-plan","title":"Spark Physical Plan","description":"Prophecy deployment is flexible and supports multiple mechanisms","sidebar":"defaultSidebar"},"spark-internals/shuffle-details":{"id":"spark-internals/shuffle-details","title":"Shuffle Details","description":"Prophecy deployment is flexible and supports multiple mechanisms","sidebar":"defaultSidebar"},"spark-internals/spark-internals":{"id":"spark-internals/spark-internals","title":"Spark Internals","description":"Describing the architecture of Prophecy and how it can integrate into your use cases","sidebar":"defaultSidebar"}}}')}}]);